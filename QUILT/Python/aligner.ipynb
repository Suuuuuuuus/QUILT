{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import gzip\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import secrets\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import resource\n",
    "import pandas as pd\n",
    "# import sqlite3\n",
    "# from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# from plotnine import *\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "import itertools\n",
    "import collections\n",
    "import pyreadr\n",
    "import pywfa\n",
    "from IPython.display import display_html\n",
    "\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "sys.path.append('/well/band/users/rbx225/software/lcwgsus/')\n",
    "import lcwgsus\n",
    "from lcwgsus.variables import *\n",
    "from warnings import simplefilter\n",
    "from hla_phase import *\n",
    "from hla_align_functions import *\n",
    "from hla_align import *\n",
    "\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_read(reads, ref, refseq, q):\n",
    "    for i, (seq, bq) in enumerate(zip(reads['sequence'], reads['base_quality'])):\n",
    "        result = ref(seq)\n",
    "        refseq_aligned = refseq[result.pattern_start:result.pattern_end]\n",
    "        seq_aligned = seq[result.text_start:result.text_end]\n",
    "        likelihood_per_read_per_allele1 = calculate_score_per_alignment(seq_aligned, refseq_aligned, bq)\n",
    "#         scores_mat[i, j] = likelihood_per_read_per_allele\n",
    "    for i, (seq, bq) in enumerate(zip(reads['rev_seq'], reads['rev_bq'])):\n",
    "        result = ref(seq)\n",
    "        refseq_aligned = refseq[result.pattern_start:result.pattern_end]\n",
    "        seq_aligned = seq[result.text_start:result.text_end]\n",
    "        likelihood_per_read_per_allele2 = calculate_score_per_alignment(seq_aligned, refseq_aligned, bq)\n",
    "#         rev_scores_mat[i, j] = likelihood_per_read_per_allele\n",
    "    return likelihood_per_read_per_allele1, likelihood_per_read_per_allele2\n",
    "\n",
    "def multi_calculate_loglikelihood_per_read(reads, db, temperature=1):\n",
    "    reads['rev_seq'] = reads['sequence'].apply(reverse_complement)\n",
    "    reads['rev_bq'] = reads['base_quality'].apply(lambda bq: bq[::-1])\n",
    "\n",
    "    scores_mat = np.zeros((reads.shape[0], db.shape[1]))\n",
    "    rev_scores_mat = np.zeros((reads.shape[0], db.shape[1]))\n",
    "    \n",
    "    manager = multiprocessing.Manager()\n",
    "    q = manager.Queue()\n",
    "    processes = []\n",
    "    \n",
    "    for j, a in enumerate(db.columns[:10]):\n",
    "        refseq = (''.join(db[a].tolist())).replace('.', '')\n",
    "        ref = pywfa.WavefrontAligner(refseq)\n",
    "        for i, (seq, bq) in enumerate(zip(reads['sequence'], reads['base_quality'])):\n",
    "            tmp = multiprocessing.Process(target=per_read,\n",
    "                                              args=(reads, ref, refseq, q))\n",
    "            tmp.start()\n",
    "            processes.append(tmp)\n",
    "\n",
    "        for process in processes:\n",
    "            process.join()\n",
    "        res_lst = []\n",
    "        while not q.empty():\n",
    "            res_lst.append(q.get())\n",
    "        else:\n",
    "            for res in res_lst:\n",
    "                scores_mat[i, j] = res[0]\n",
    "                rev_scores_mat[i, j] = res[1]\n",
    "\n",
    "    reads = reads.drop(columns = ['rev_seq', 'rev_bq'])\n",
    "    scores_mat = np.maximum(scores_mat, rev_scores_mat)\n",
    "    likelihood_mat = np.exp(scores_mat/temperature)/np.sum(np.exp(scores_mat/temperature), axis = 1, keepdims = True)\n",
    "    loglikelihood_mat = np.log(likelihood_mat)\n",
    "    return loglikelihood_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_allele(j, a, db, reads, q):\n",
    "    refseq = (''.join(db[a].tolist())).replace('.', '')\n",
    "    ref = pywfa.WavefrontAligner(refseq)\n",
    "    scores_mat_ary1 = []\n",
    "    scores_mat_ary2 = []\n",
    "    for i, (seq, bq) in enumerate(zip(reads['sequence'], reads['base_quality'])):\n",
    "        result = ref(seq)\n",
    "        refseq_aligned = refseq[result.pattern_start:result.pattern_end]\n",
    "        seq_aligned = seq[result.text_start:result.text_end]\n",
    "        likelihood_per_read_per_allele1 = calculate_score_per_alignment(seq_aligned, refseq_aligned, bq)\n",
    "        scores_mat_ary1.append(likelihood_per_read_per_allele1)\n",
    "    for i, (seq, bq) in enumerate(zip(reads['rev_seq'], reads['rev_bq'])):\n",
    "        result = ref(seq)\n",
    "        refseq_aligned = refseq[result.pattern_start:result.pattern_end]\n",
    "        seq_aligned = seq[result.text_start:result.text_end]\n",
    "        likelihood_per_read_per_allele2 = calculate_score_per_alignment(seq_aligned, refseq_aligned, bq)\n",
    "        scores_mat_ary2.append(likelihood_per_read_per_allele2)\n",
    "    \n",
    "    q.put([j, np.array(scores_mat_ary1), np.array(scores_mat_ary2)])\n",
    "    \n",
    "def multi_calculate_loglikelihood_per_allele(reads, db, temperature=1):\n",
    "    reads['rev_seq'] = reads['sequence'].apply(reverse_complement)\n",
    "    reads['rev_bq'] = reads['base_quality'].apply(lambda bq: bq[::-1])\n",
    "\n",
    "    scores_mat = np.zeros((reads.shape[0], db.shape[1]))\n",
    "    rev_scores_mat = np.zeros((reads.shape[0], db.shape[1]))\n",
    "    \n",
    "    manager = multiprocessing.Manager()\n",
    "    q = manager.Queue()\n",
    "    processes = []\n",
    "    \n",
    "    for j, a in enumerate(db.columns[:10]):\n",
    "        tmp = multiprocessing.Process(target=per_allele,\n",
    "                                          args=(j, a, db, reads, q))\n",
    "        tmp.start()\n",
    "        processes.append(tmp)\n",
    "\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    res_lst = []\n",
    "    while not q.empty():\n",
    "        res_lst.append(q.get())\n",
    "    else:\n",
    "        for res in res_lst:\n",
    "            j = res[0]\n",
    "            scores_mat[:, j] = res[1]\n",
    "            rev_scores_mat[:, j] = res[2]\n",
    "\n",
    "    reads = reads.drop(columns = ['rev_seq', 'rev_bq'])\n",
    "    scores_mat = np.maximum(scores_mat, rev_scores_mat)\n",
    "    likelihood_mat = np.exp(scores_mat/temperature)/np.sum(np.exp(scores_mat/temperature), axis = 1, keepdims = True)\n",
    "    loglikelihood_mat = np.log(likelihood_mat)\n",
    "    return loglikelihood_mat   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226.36023259162903\n"
     ]
    }
   ],
   "source": [
    "# gene = 'DRB1'\n",
    "# hla_gene_information = pd.read_csv('/well/band/users/rbx225/software/QUILT_sus/hla_ancillary_files/hla_gene_information.tsv', sep = ' ')\n",
    "# bam = \"/well/band/users/rbx225/GAMCC/data/bams/IDT0482.bam\"\n",
    "# hla_gene_information = pd.read_csv('/well/band/users/rbx225/software/QUILT_sus/hla_ancillary_files/hla_gene_information.tsv', sep = ' ')\n",
    "# db = pd.read_csv(f'/well/band/users/rbx225/recyclable_files/hla_reference_files/v3570_aligners/{gene}.ssv', sep = ' ')\n",
    "\n",
    "# reads_apart_max=1000\n",
    "# temperature=100\n",
    "# n_mismatches=5\n",
    "# assumed_bq=0.001\n",
    "\n",
    "# reads1 = get_chr6_reads(gene, bam, hla_gene_information, reads_apart_max)\n",
    "# reads2 = get_hla_reads(gene, bam, reads_apart_max)\n",
    "\n",
    "# if reads1.empty:\n",
    "#     reads1 = reads2.iloc[:2, :] if not reads2.empty else pd.DataFrame()\n",
    "# elif reads2.empty:\n",
    "#     reads2 = reads1.iloc[:2, :]\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# rl = reads1['sequence'].str.len().mode().values[0]\n",
    "\n",
    "start = time.time()\n",
    "# likemat1 = multi_calculate_loglikelihood_per_allele(reads1, db, temperature = 1)\n",
    "likemat1 = calculate_loglikelihood(reads1, db, temperature = 1)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# likemat2 = calculate_loglikelihood1(reads2, db)\n",
    "# min_valid_prob = np.log(math.comb(rl, n_mismatches)) + n_mismatches*np.log(assumed_bq) + (rl - n_mismatches)*np.log(1 - assumed_bq)\n",
    "\n",
    "# valid_indices1 = np.any(likemat1 >= min_valid_prob, axis=1)\n",
    "# valid_indices2 = np.any(likemat2 >= min_valid_prob, axis=1)\n",
    "# likemat1, reads1 = likemat1[valid_indices1], reads1[valid_indices1]\n",
    "# likemat2, reads2 = likemat2[valid_indices2], reads2[valid_indices2]\n",
    "\n",
    "# likemat_all = np.vstack((likemat1, likemat2))\n",
    "\n",
    "# id1, id2 = reads1.iloc[:, 0].to_numpy(), reads2.iloc[:, 0].to_numpy()\n",
    "\n",
    "# readind = (reads1.iloc[:, 1].astype(int) // 64) % 4\n",
    "# readind2 = (reads2.iloc[:, 1].astype(int) // 64) % 4\n",
    "# mate_indicator = np.concatenate((readind, readind2))\n",
    "\n",
    "# ids_all = np.concatenate((id1, id2))\n",
    "# unique_ids = np.unique(ids_all)\n",
    "# likemat_mate = np.zeros((len(unique_ids), likemat_all.shape[1]))\n",
    "\n",
    "# for i, uid in enumerate(unique_ids):\n",
    "#     t1 = likemat_all[ids_all == uid, :]\n",
    "#     t2 = mate_indicator[ids_all == uid]\n",
    "#     if len(t2) > 0:\n",
    "#         likemat_mate[i, :] = np.sum(t1[t2 > 0], axis=0)\n",
    "\n",
    "# valid_mask = likemat_mate.max(axis=1) >= min_valid_prob\n",
    "# likemat_mate = likemat_mate[valid_mask]\n",
    "# likemat_norm = 0.5 * np.exp(likemat_mate - likemat_mate.max(axis=1, keepdims=True)) + 1e-100\n",
    "\n",
    "# likemat_paired = likemat_norm.T @ likemat_norm\n",
    "# likemat_paired = pd.DataFrame(likemat_paired, index=db.columns, columns=db.columns)\n",
    "\n",
    "# likemat_mate = pd.DataFrame(likemat_mate, index = unique_ids[valid_mask], columns=db.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = 'DRB1'\n",
    "hla_gene_information = pd.read_csv('/well/band/users/rbx225/software/QUILT_sus/hla_ancillary_files/hla_gene_information.tsv', sep = ' ')\n",
    "bam = \"/well/band/users/rbx225/GAMCC/data/bams/IDT0482.bam\"\n",
    "\n",
    "# db = process_db_genfile(gene, ipd_gen_file_dir, hla_gene_information)\n",
    "# db.to_csv(f'/well/band/users/rbx225/recyclable_files/hla_reference_files/v3570_aligners/{gene}.ssv', sep = ' ', index = False, header = True)\n",
    "\n",
    "db = pd.read_csv(f'/well/band/users/rbx225/recyclable_files/hla_reference_files/v3570_aligners/{gene}.ssv', sep = ' ')\n",
    "\n",
    "r1, r2, mate, pair = hla_aligner(gene, bam, db, hla_gene_information)\n",
    "\n",
    "r1.to_csv(outdir + '/reads1.csv', header = False, index = False)\n",
    "r2.to_csv(outdir + '/reads2.csv', header = False, index = False)\n",
    "\n",
    "pd.set_option('display.float_format', '{:.6e}'.format)\n",
    "mate.to_csv(outdir + '/mate_likelihood_matrix.ssv', index=True, header=True, sep = ' ')\n",
    "pair.to_csv(outdir + '/pair_likelihood_matrix.ssv', index=True, header=True, sep = ' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
