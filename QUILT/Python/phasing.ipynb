{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import gzip\n",
    "import time\n",
    "import json\n",
    "import secrets\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import resource\n",
    "import pandas as pd\n",
    "# import sqlite3\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# from plotnine import *\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "# from collections import Counter\n",
    "# import seaborn as sns\n",
    "# import matplotlib.colors as mcolors\n",
    "# from matplotlib.ticker import FuncFormatter\n",
    "import itertools\n",
    "import collections\n",
    "import pyreadr\n",
    "# import patchworklib as pw\n",
    "# sys.path.append('/well/band/users/rbx225/software/lcwgsus/')\n",
    "# import lcwgsus\n",
    "# from lcwgsus.variables import *\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Genuine logics changed from the main script were marked by string **X** in the original R files.\n",
    "# Simplicity changes were marked by string **Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = 'DRB1'\n",
    "nucleotides = ['A', 'T', 'C', 'G']\n",
    "ipd_gen_file = '/Users/sus_zhang/Desktop/Suuuuuuuus/misc_data/alignments/' + gene + '_gen.txt'\n",
    "if not os.path.exists(ipd_gen_file):\n",
    "    ipd_gen_file = '/well/band/users/rbx225/recyclable_files/hla/alignments/' + gene + '_gen.txt'\n",
    "\n",
    "hla_gene_information = pd.read_csv('/well/band/users/rbx225/software/QUILT_sus/hla_ancillary_files/hlagenes.txt', sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ipd_gen_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "gDNA_idx = []\n",
    "names = []\n",
    "i = 0\n",
    "while len(gDNA_idx) < 2:\n",
    "    l = lines[i]\n",
    "    if 'gDNA' in l:\n",
    "        gDNA_idx.append(i)\n",
    "    elif l.lstrip(' ').split(' ')[0].startswith(gene + '*'):\n",
    "        name = l.lstrip(' ').split(' ')[0]\n",
    "        names.append(name)\n",
    "    i += 1\n",
    "    \n",
    "first_base = int(lines[gDNA_idx[0]].split(' ')[-1].split('\\n')[0])\n",
    "n_alleles = gDNA_idx[1] - gDNA_idx[0] - 3\n",
    "\n",
    "alleles_dict = {k:'' for k in names}\n",
    "for i, s in enumerate(lines):\n",
    "    r = s.lstrip(' ')\n",
    "    if r.startswith(gene):\n",
    "        r = r.rstrip(' \\n')\n",
    "        name = r.split(' ')[0]\n",
    "        sequence = r.split(' ')[2:]\n",
    "        sequence = ''.join(sequence)\n",
    "        alleles_dict[name] = alleles_dict[name] + sequence\n",
    "    \n",
    "df = pd.DataFrame({key: list(value) for key, value in alleles_dict.items()}).T\n",
    "df = df.drop(columns=df.columns[df.eq('|').all()])\n",
    "df.columns = range(df.shape[1])\n",
    "\n",
    "length = len(df.columns)\n",
    "positions = [first_base]*length\n",
    "\n",
    "df.loc[len(df)] = positions\n",
    "\n",
    "r_idx = len(df) - 1\n",
    "for i in df.columns[1:]:\n",
    "    if df.iloc[0, i] == '.':\n",
    "        df.iloc[r_idx, i] = df.iloc[r_idx, i-1]\n",
    "    else:\n",
    "        if df.iloc[r_idx, i-1] != -1:\n",
    "            df.iloc[r_idx, i] = df.iloc[r_idx, i-1] + 1\n",
    "        else:\n",
    "            df.iloc[r_idx, i] = df.iloc[r_idx, i-1] + 2 # No zero in position. ATG is encoded by 1.\n",
    "df.columns = df.iloc[r_idx]\n",
    "df = df.iloc[:r_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_refdir = '/well/band/users/rbx225/GAMCC/results/hla/imputation/ref_panel/QUILT_ref_files/'\n",
    "auxiliary_dir = '/well/band/users/rbx225/GAMCC/results/hla/imputation/ref_panel/auxiliary_files/' \n",
    "all_haplotypes = pyreadr.read_r(original_refdir + 'quilt.hrc.hla.all.haplotypes.RData') # See if it is possible to remove the 32 bases dependency\n",
    "snpformatalleles = pyreadr.read_r(original_refdir + 'hlaDRB1snpformatalleles.RData')\n",
    "fullallelesfilledin = pyreadr.read_r(original_refdir + 'HLADRB1fullallelesfilledin.RData')\n",
    "full = pyreadr.read_r(original_refdir + 'hlaDRB1full.RData')\n",
    "\n",
    "# Check these two: should contain 1kg HLA types\n",
    "hlatypes = pd.read_csv(auxiliary_dir + '20181129_HLA_types_full_1000_Genomes_Project_panel.txt', sep = '\\t')\n",
    "ref_samples = pd.read_csv(auxiliary_dir + 'oneKG.samples', sep = ' ')\n",
    "# hlatypes = hlatypes[match(reference_samples[,1],hlatypes[,3]),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>POP</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>SEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>HG00096</td>\n",
       "      <td>HG00096</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>HG00097</td>\n",
       "      <td>HG00097</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00099</td>\n",
       "      <td>HG00099</td>\n",
       "      <td>HG00099</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00100</td>\n",
       "      <td>HG00100</td>\n",
       "      <td>HG00100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00101</td>\n",
       "      <td>HG00101</td>\n",
       "      <td>HG00101</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>NA21137</td>\n",
       "      <td>NA21137</td>\n",
       "      <td>NA21137</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>NA21141</td>\n",
       "      <td>NA21141</td>\n",
       "      <td>NA21141</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>NA21142</td>\n",
       "      <td>NA21142</td>\n",
       "      <td>NA21142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>NA21143</td>\n",
       "      <td>NA21143</td>\n",
       "      <td>NA21143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>NA21144</td>\n",
       "      <td>NA21144</td>\n",
       "      <td>NA21144</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3202 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SAMPLE      POP    GROUP  SEX\n",
       "0     HG00096  HG00096  HG00096    2\n",
       "1     HG00097  HG00097  HG00097    2\n",
       "2     HG00099  HG00099  HG00099    2\n",
       "3     HG00100  HG00100  HG00100    2\n",
       "4     HG00101  HG00101  HG00101    2\n",
       "...       ...      ...      ...  ...\n",
       "3197  NA21137  NA21137  NA21137    2\n",
       "3198  NA21141  NA21141  NA21141    2\n",
       "3199  NA21142  NA21142  NA21142    2\n",
       "3200  NA21143  NA21143  NA21143    2\n",
       "3201  NA21144  NA21144  NA21144    2\n",
       "\n",
       "[3202 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_samples_removed = ref_samples[~ref_samples['SAMPLE'].isin(hlatypes['Sample ID'].tolist())]\n",
    "samples_to_remove = ref_samples_removed['SAMPLE'].tolist()\n",
    "reference_exclude_samplelist_file = ''\n",
    "\n",
    "if reference_exclude_samplelist_file != '':\n",
    "    samples_to_remove = samples_to_remove + lcwgsus.read_tsv_as_lst(reference_exclude_samplelist_file)\n",
    "# if samples_to_remove is not none, save to \"hlauntyped.exclude.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Population</th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>HLA-A 1</th>\n",
       "      <th>HLA-A 2</th>\n",
       "      <th>HLA-B 1</th>\n",
       "      <th>HLA-B 2</th>\n",
       "      <th>HLA-C 1</th>\n",
       "      <th>HLA-C 2</th>\n",
       "      <th>HLA-DQB1 1</th>\n",
       "      <th>HLA-DQB1 2</th>\n",
       "      <th>HLA-DRB1 1</th>\n",
       "      <th>HLA-DRB1 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFR</td>\n",
       "      <td>ACB</td>\n",
       "      <td>HG01879</td>\n",
       "      <td>23:01</td>\n",
       "      <td>68:02</td>\n",
       "      <td>13:02</td>\n",
       "      <td>42:01</td>\n",
       "      <td>08:04</td>\n",
       "      <td>17:01</td>\n",
       "      <td>02:02</td>\n",
       "      <td>04:02</td>\n",
       "      <td>03:02</td>\n",
       "      <td>09:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFR</td>\n",
       "      <td>ACB</td>\n",
       "      <td>HG01880</td>\n",
       "      <td>33:03</td>\n",
       "      <td>68:02</td>\n",
       "      <td>40:06</td>\n",
       "      <td>42:01</td>\n",
       "      <td>12:02</td>\n",
       "      <td>17:01</td>\n",
       "      <td>02:01</td>\n",
       "      <td>03:04</td>\n",
       "      <td>03:01</td>\n",
       "      <td>11:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFR</td>\n",
       "      <td>ACB</td>\n",
       "      <td>HG01882</td>\n",
       "      <td>23:01</td>\n",
       "      <td>34:02</td>\n",
       "      <td>07:02</td>\n",
       "      <td>44:50</td>\n",
       "      <td>04:01</td>\n",
       "      <td>07:02</td>\n",
       "      <td>06:02</td>\n",
       "      <td>06:02</td>\n",
       "      <td>15:03</td>\n",
       "      <td>15:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFR</td>\n",
       "      <td>ACB</td>\n",
       "      <td>HG01883</td>\n",
       "      <td>02:01</td>\n",
       "      <td>68:02</td>\n",
       "      <td>53:01</td>\n",
       "      <td>44:03</td>\n",
       "      <td>04:01</td>\n",
       "      <td>04:01</td>\n",
       "      <td>02:02</td>\n",
       "      <td>06:02</td>\n",
       "      <td>13:03</td>\n",
       "      <td>15:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFR</td>\n",
       "      <td>ACB</td>\n",
       "      <td>HG01885</td>\n",
       "      <td>03:01</td>\n",
       "      <td>33:03</td>\n",
       "      <td>35:01</td>\n",
       "      <td>35:01</td>\n",
       "      <td>04:01</td>\n",
       "      <td>07:18</td>\n",
       "      <td>02:02</td>\n",
       "      <td>03:19</td>\n",
       "      <td>13:04</td>\n",
       "      <td>07:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>SAS</td>\n",
       "      <td>STU</td>\n",
       "      <td>HG04114</td>\n",
       "      <td>02:01</td>\n",
       "      <td>24:02</td>\n",
       "      <td>52:01</td>\n",
       "      <td>55:01</td>\n",
       "      <td>01:02</td>\n",
       "      <td>12:02</td>\n",
       "      <td>03:02</td>\n",
       "      <td>06:03</td>\n",
       "      <td>13:01</td>\n",
       "      <td>04:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>SAS</td>\n",
       "      <td>STU</td>\n",
       "      <td>HG04127</td>\n",
       "      <td>02:11</td>\n",
       "      <td>24:02</td>\n",
       "      <td>15:05</td>\n",
       "      <td>52:01</td>\n",
       "      <td>03:03</td>\n",
       "      <td>12:02</td>\n",
       "      <td>06:09</td>\n",
       "      <td>06:09</td>\n",
       "      <td>13:01</td>\n",
       "      <td>13:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>SAS</td>\n",
       "      <td>STU</td>\n",
       "      <td>HG04210</td>\n",
       "      <td>02:01</td>\n",
       "      <td>24:02</td>\n",
       "      <td>15:25</td>\n",
       "      <td>35:01</td>\n",
       "      <td>04:01</td>\n",
       "      <td>07:26</td>\n",
       "      <td>05:02</td>\n",
       "      <td>06:03</td>\n",
       "      <td>13:01</td>\n",
       "      <td>14:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>SAS</td>\n",
       "      <td>STU</td>\n",
       "      <td>HG04227</td>\n",
       "      <td>01:01</td>\n",
       "      <td>01:01</td>\n",
       "      <td>57:01</td>\n",
       "      <td>44:03</td>\n",
       "      <td>06:02</td>\n",
       "      <td>07:06</td>\n",
       "      <td>03:03</td>\n",
       "      <td>06:01</td>\n",
       "      <td>07:01</td>\n",
       "      <td>15:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>SAS</td>\n",
       "      <td>STU</td>\n",
       "      <td>HG04229</td>\n",
       "      <td>11:01</td>\n",
       "      <td>24:07</td>\n",
       "      <td>13:01</td>\n",
       "      <td>37:01</td>\n",
       "      <td>04:03</td>\n",
       "      <td>06:02</td>\n",
       "      <td>04:02</td>\n",
       "      <td>06:02</td>\n",
       "      <td>04:10</td>\n",
       "      <td>15:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2693 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Region Population Sample ID HLA-A 1 HLA-A 2 HLA-B 1 HLA-B 2 HLA-C 1  \\\n",
       "0       AFR        ACB   HG01879   23:01   68:02   13:02   42:01   08:04   \n",
       "1       AFR        ACB   HG01880   33:03   68:02   40:06   42:01   12:02   \n",
       "2       AFR        ACB   HG01882   23:01   34:02   07:02   44:50   04:01   \n",
       "3       AFR        ACB   HG01883   02:01   68:02   53:01   44:03   04:01   \n",
       "4       AFR        ACB   HG01885   03:01   33:03   35:01   35:01   04:01   \n",
       "...     ...        ...       ...     ...     ...     ...     ...     ...   \n",
       "2688    SAS        STU   HG04114   02:01   24:02   52:01   55:01   01:02   \n",
       "2689    SAS        STU   HG04127   02:11   24:02   15:05   52:01   03:03   \n",
       "2690    SAS        STU   HG04210   02:01   24:02   15:25   35:01   04:01   \n",
       "2691    SAS        STU   HG04227   01:01   01:01   57:01   44:03   06:02   \n",
       "2692    SAS        STU   HG04229   11:01   24:07   13:01   37:01   04:03   \n",
       "\n",
       "     HLA-C 2 HLA-DQB1 1 HLA-DQB1 2 HLA-DRB1 1 HLA-DRB1 2  \n",
       "0      17:01      02:02      04:02      03:02      09:01  \n",
       "1      17:01      02:01      03:04      03:01      11:06  \n",
       "2      07:02      06:02      06:02      15:03      15:03  \n",
       "3      04:01      02:02      06:02      13:03      15:03  \n",
       "4      07:18      02:02      03:19      13:04      07:01  \n",
       "...      ...        ...        ...        ...        ...  \n",
       "2688   12:02      03:02      06:03      13:01      04:03  \n",
       "2689   12:02      06:09      06:09      13:01      13:02  \n",
       "2690   07:26      05:02      06:03      13:01      14:02  \n",
       "2691   07:06      03:03      06:01      07:01      15:01  \n",
       "2692   06:02      04:02      06:02      04:10      15:01  \n",
       "\n",
       "[2693 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oldsnpinfo -> prepared_vcf\n",
    "# ss -> variant_alleles\n",
    "# samples -> alleles\n",
    "# qq -> positions\n",
    "knownvarsfiltered = snpformatalleles['knownvarsfiltered'].copy()\n",
    "resmat = snpformatalleles['resmat'].copy()\n",
    "knownvarsfiltered = knownvarsfiltered[knownvarsfiltered[1].isin(nucleotides) & knownvarsfiltered[2].isin(nucleotides)].reset_index(drop = True)\n",
    "\n",
    "ids = \"chr6:\" + knownvarsfiltered[0].astype(str)\n",
    "prepared_vcf = pd.concat([ids, knownvarsfiltered], axis=1)\n",
    "alleles = resmat.index\n",
    "prepared_vcf.columns = [\"id\", \"position\", \"a0\", \"a1\"]\n",
    "prepared_vcf['position']  = prepared_vcf['position'].astype(int)\n",
    "\n",
    "ourpos = fullallelesfilledin['ourpos']['ourpos'].tolist()\n",
    "fullalleles = fullallelesfilledin['fullalleles'].copy()\n",
    "\n",
    "retained_index = []\n",
    "variant_alleles = pd.DataFrame(index=fullalleles.index)\n",
    "\n",
    "for i in range(len(prepared_vcf)):\n",
    "    _, pos, ref, alt = prepared_vcf.iloc[i,:]\n",
    "    index = np.where(ourpos == pos)[0]\n",
    "    if index.size != 0:\n",
    "        index = index[0]\n",
    "        retained_index.append(index)\n",
    "        variant_alleles[variant_alleles.shape[1]] = fullalleles[index].map({ref: '0', alt: '1'}).fillna(fullalleles[index])\n",
    "    else:\n",
    "        prepared_vcf.iloc[i,2] = 'tbr' # tbr: To be removed\n",
    "\n",
    "prepared_vcf = prepared_vcf[prepared_vcf['a0'] != 'tbr'].reset_index(drop = True)\n",
    "variant_alleles = variant_alleles.T\n",
    "\n",
    "positions = prepared_vcf['position'].astype(float).values  # Convert position to double\n",
    "\n",
    "zz = np.zeros(variant_alleles.shape[0]) \n",
    "for i in range(len(zz)):\n",
    "    zz[i] = np.sum(ourpos == positions[i])\n",
    "zz2 = np.zeros_like(zz)\n",
    "zz2 = np.sum(~((variant_alleles == '0') | (variant_alleles == '1')), axis=1)\n",
    "zz3 = np.zeros_like(zz)\n",
    "for i in range(len(zz3)):\n",
    "    zz3[i] = np.sum(positions == positions[i])\n",
    "zz4 = np.sum(~((variant_alleles == '0') | (variant_alleles == '1') | (variant_alleles == \".\")), axis=1)\n",
    "filter_conditions = (zz3 == 1) & (zz == 1) & (zz2 < variant_alleles.shape[1] * 0.1) & (zz2 < 0.5 * np.sum(variant_alleles == '1', axis=1)) & (zz4 == 0)\n",
    "\n",
    "# keep sites uniquely mapping, not overlapping another SNP, with at most 10% gaps and 2-fold more non-ancestral than gaps\n",
    "snpinfo = prepared_vcf.loc[filter_conditions, :]\n",
    "variant_alleles = variant_alleles.loc[filter_conditions, :]\n",
    "variant_alleles[variant_alleles == \".\"] = 0 # indels set to 0\n",
    "haps = variant_alleles.copy().reset_index(drop = True) # Now everything is in string format\n",
    "\n",
    "# Continue from line 244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the samples matrix\n",
    "samples = np.array(alleles).reshape(-1, 1)\n",
    "c1 = [s[0].split('*') for s in samples]\n",
    "\n",
    "vv = np.empty((samples.shape[0], 3), dtype=object)\n",
    "ww = [c[1] for c in c1]\n",
    "\n",
    "for i in range(len(c1)):\n",
    "    vv[i, 0] = c1[i][0]\n",
    "\n",
    "c1 = [w.split(':') for w in ww]\n",
    "\n",
    "for i in range(len(c1)):\n",
    "    vv[i, 1] = c1[i][0]\n",
    "    vv[i, 2] = c1[i][1]\n",
    "\n",
    "fourdigit = [f\"{vv[i, 1]}:{vv[i, 2]}\" for i in range(len(vv))]\n",
    "\n",
    "ufourdigit = np.unique(fourdigit)\n",
    "\n",
    "# Step 2: Handle the haps matrix\n",
    "haps = np.array(haps, dtype=float)\n",
    "\n",
    "newhaps = np.empty((haps.shape[0], len(ufourdigit)))\n",
    "\n",
    "for i in range(newhaps.shape[1]):\n",
    "    tt = np.where(np.array(fourdigit) == ufourdigit[i])[0]\n",
    "    if len(tt) < 2:\n",
    "        tt = np.concatenate((tt, tt))\n",
    "    newhaps[:, i] = np.mean(haps[:, tt], axis=1)\n",
    "\n",
    "# Step 3: Match position strings (v1, v2, v2f)\n",
    "v1 = [' '.join(map(str, p)) for p in pos[:, [1, 2, 3]]]\n",
    "v2 = [' '.join(map(str, s)) for s in snpinfo[:, [1, 2, 3]]]\n",
    "v2f = [' '.join(map(str, s[::-1])) for s in snpinfo[:, [1, 3, 2]]]\n",
    "\n",
    "# Step 4: Find matches\n",
    "same = [v2.index(v) if v in v2 else None for v in v1]\n",
    "flipped = [v2f.index(v) if v in v2f else None for v in v1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Find indices where 'same' or 'flipped' is not NaN\n",
    "locs = [i for i in range(len(same)) if same[i] is not None or flipped[i] is not None]\n",
    "\n",
    "# Step 2: Update 'same' based on 'flipped'\n",
    "if np.sum([f is not None for f in flipped]):\n",
    "    for i in locs:\n",
    "        if flipped[i] is not None:\n",
    "            same[i] = flipped[i]\n",
    "\n",
    "# Step 3: Filter 'same' and 'flipped' by 'locs'\n",
    "same = [same[i] for i in locs]\n",
    "flipped = [flipped[i] for i in locs]\n",
    "\n",
    "# Step 4: Subset 'newhaps' matrix using 'same'\n",
    "newhaps2 = newhaps[same, :]\n",
    "\n",
    "# Step 5: Adjust 'newhaps2' based on 'flipped'\n",
    "if np.sum([f is not None for f in flipped]):\n",
    "    for i in range(len(flipped)):\n",
    "        if flipped[i] is not None:\n",
    "            newhaps2[i, :] = 1 - newhaps2[i, :]\n",
    "\n",
    "# Step 6: Define the translate function\n",
    "def translate(matchlist):\n",
    "    qq = np.array(matchlist)\n",
    "    signs = np.zeros(len(matchlist), dtype=int)\n",
    "    \n",
    "    signs[qq < 0] = 1\n",
    "    qq[signs == 1] += 2**31\n",
    "    \n",
    "    res = np.zeros((len(matchlist), 0), dtype=float)\n",
    "    \n",
    "    for i in range(31):\n",
    "        tempres = qq % 2\n",
    "        qq = (qq - tempres) // 2\n",
    "        res = np.hstack((res, tempres.reshape(-1, 1)))\n",
    "    \n",
    "    res = np.hstack((res, signs.reshape(-1, 1)))\n",
    "    \n",
    "    res[res == 1] = 0.999\n",
    "    res[res == 0] = 0.001\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Step 1: Find the relevant columns using a pattern\n",
    "region_pattern = f\"HLA.{region}.\"\n",
    "cols = [i for i, col in enumerate(hlatypes2.columns) if re.search(region_pattern, col)]\n",
    "\n",
    "# Step 2: Extract and clean 'ourtypes1'\n",
    "ourtypes1 = hlatypes2.iloc[:, cols[0]].astype(str).tolist()\n",
    "ourtypes1 = [re.sub(r\"\\*\", \"\", t) for t in ourtypes1]\n",
    "\n",
    "# Step 3: If multiple types exist, assign the lowest number\n",
    "vv = [t.split('/') for t in ourtypes1]\n",
    "for i in range(len(ourtypes1)):\n",
    "    ourtypes1[i] = vv[i][0]\n",
    "\n",
    "# Step 4: Extract and clean 'ourtypes2'\n",
    "ourtypes2 = hlatypes2.iloc[:, cols[1]].astype(str).tolist()\n",
    "ourtypes2 = [re.sub(r\"\\*\", \"\", t) for t in ourtypes2]\n",
    "\n",
    "# Step 5: Assign the lowest number if there are multiple possible types\n",
    "vv = [t.split('/') for t in ourtypes2]\n",
    "for i in range(len(ourtypes2)):\n",
    "    ourtypes2[i] = vv[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Define start and end ranges\n",
    "startandend = range(locs[0], locs[-1] + 1)\n",
    "\n",
    "start32 = (startandend[0] // 32) + 1  # per-chunk start\n",
    "end32 = (startandend[-1] // 32) + 1\n",
    "\n",
    "start = (start32 - 1) * 32 + 1\n",
    "end = end32 * 32\n",
    "\n",
    "# Step 2: Slice distinctHapsIE, distinctHapsB, and rhb_t matrices\n",
    "tempIE = distinctHapsIE[:, start-1:end]\n",
    "tempB = distinctHapsB[:, start32-1:end32]\n",
    "\n",
    "# Assuming rhb_t is a matrix of 1s or -1s for strand information\n",
    "temp = rhb_t[:, start32-1:end32]\n",
    "\n",
    "# Step 3: Initialize temp2 matrix\n",
    "temp2 = np.empty((temp.shape[0], tempIE.shape[1]))\n",
    "\n",
    "# Step 4: Define 'cc' vector (for NA interpretation)\n",
    "cc = np.concatenate((np.full(31, 0.001), [0.999]))\n",
    "\n",
    "# Step 5: Iterate over columns of temp\n",
    "for i in range(temp.shape[1]):\n",
    "    start_col = (i * 32)\n",
    "    end_col = (i + 1) * 32\n",
    "\n",
    "    # Match temp with tempB and fill temp2\n",
    "    temp2[:, start_col:end_col] = tempIE[np.searchsorted(tempB[:, i], temp[:, i]), start_col:end_col]\n",
    "\n",
    "    # Handle NA (None) cases in temp\n",
    "    cc2 = np.where(np.isnan(temp[:, i]))[0]\n",
    "    if len(cc2) > 0:\n",
    "        cc3 = np.tile(cc, (len(cc2), 1))\n",
    "        temp2[cc2, start_col:end_col] = cc3\n",
    "\n",
    "    # Final step: Handle NA in temp2 for the final column of the block\n",
    "    needed = np.where(np.isnan(temp2[:, end_col-1]))[0]\n",
    "    if len(needed) > 0:\n",
    "        temp2[needed, start_col:end_col] = translate(temp[needed, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Adjust `locs` and extract `hrchapstomatch`\n",
    "newlocs = locs - start + 1\n",
    "hrchapstomatch = temp2[:, newlocs-1]  # Adjust for Python's zero-indexing\n",
    "\n",
    "# Step 2: Split into first and second alleles\n",
    "hrcfirstalleles = hrchapstomatch[::2, :]\n",
    "hrcsecondalleles = hrchapstomatch[1::2, :]\n",
    "\n",
    "# Step 3: Initialize temp and handle `ourtypes1`\n",
    "temp = np.full(len(ourtypes1), -1)\n",
    "temp[np.isin(ourtypes1, newhaps2.columns)] = 1\n",
    "\n",
    "# Step 4: Predict first alleles\n",
    "predfirstalleles = np.empty((len(temp), newhaps2.shape[0]))\n",
    "predfirstalleles[temp == 1, :] = newhaps2.loc[:, ourtypes1[temp == 1]].T\n",
    "\n",
    "# Step 5: Handle `ourtypes2`\n",
    "temp = np.full(len(ourtypes2), -1)\n",
    "temp[np.isin(ourtypes2, newhaps2.columns)] = 1\n",
    "\n",
    "# Step 6: Predict second alleles\n",
    "predsecondalleles = np.empty((len(temp), newhaps2.shape[0]))\n",
    "predsecondalleles[temp == 1, :] = newhaps2.loc[:, ourtypes2[temp == 1]].T\n",
    "\n",
    "# Step 7: Compute distances\n",
    "dist11 = np.sum(np.abs(hrcfirstalleles - predfirstalleles), axis=1)\n",
    "dist12 = np.sum(np.abs(hrcfirstalleles - predsecondalleles), axis=1)\n",
    "dist21 = np.sum(np.abs(hrcsecondalleles - predfirstalleles), axis=1)\n",
    "dist22 = np.sum(np.abs(hrcsecondalleles - predsecondalleles), axis=1)\n",
    "\n",
    "# Step 8: Perform alignment and assign `w`\n",
    "w = np.zeros(len(dist11))\n",
    "w[dist11 > dist12] = 1\n",
    "w[dist11 < dist12] = -1\n",
    "w1 = w\n",
    "\n",
    "w = np.zeros(len(dist21))\n",
    "w[dist22 < dist21] = 1\n",
    "w[dist22 > dist21] = -1\n",
    "w2 = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Step 1: Calculate observed and predicted genotypes\n",
    "obsgen = hrcfirstalleles + hrcsecondalleles\n",
    "predgen = predfirstalleles + predsecondalleles\n",
    "\n",
    "# Step 2: Calculate correlations column-wise\n",
    "corr = np.empty(obsgen.shape[1])\n",
    "for i in range(obsgen.shape[1]):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        corr[i] = pearsonr(obsgen[:, i], predgen[:, i])[0] if not np.all(np.isnan(predgen[:, i])) else np.nan\n",
    "\n",
    "# Step 3: Filter columns with correlation > 0.8 and non-NA values\n",
    "valid_corr_indices = np.where((corr > 0.8) & (~np.isnan(corr)))[0]\n",
    "\n",
    "# Step 4: Compute distances for the filtered columns\n",
    "dist11 = np.sum(np.abs(hrcfirstalleles[:, valid_corr_indices] - predfirstalleles[:, valid_corr_indices]), axis=1)\n",
    "dist12 = np.sum(np.abs(hrcfirstalleles[:, valid_corr_indices] - predsecondalleles[:, valid_corr_indices]), axis=1)\n",
    "dist21 = np.sum(np.abs(hrcsecondalleles[:, valid_corr_indices] - predfirstalleles[:, valid_corr_indices]), axis=1)\n",
    "dist22 = np.sum(np.abs(hrcsecondalleles[:, valid_corr_indices] - predsecondalleles[:, valid_corr_indices]), axis=1)\n",
    "\n",
    "# Step 5: Calculate w1 and w2 based on distances\n",
    "w = np.zeros(len(dist11))\n",
    "w[dist11 < dist12] = 1\n",
    "w[dist11 > dist12] = -1\n",
    "w1 = w\n",
    "\n",
    "w = np.zeros(len(dist21))\n",
    "w[dist22 < dist21] = 1\n",
    "w[dist22 > dist21] = -1\n",
    "w2 = w\n",
    "\n",
    "# Print the contingency table of w1 and w2\n",
    "# We can use numpy's `np.histogram2d()` to create a table equivalent to `table()`\n",
    "w1_w2_table = np.histogram2d(w1, w2, bins=[[-1, 0, 1], [-1, 0, 1]])[0]\n",
    "\n",
    "# Step 6: Calculate phasing metrics\n",
    "phase1 = dist11 + dist22\n",
    "phase2 = dist12 + dist21\n",
    "\n",
    "# Step 7: Criteria for phasing\n",
    "d11 = dist11\n",
    "d21 = dist21\n",
    "d12 = dist12\n",
    "d22 = dist22\n",
    "\n",
    "phased = (\n",
    "    (~np.isnan(phase1) & ~np.isnan(phase2) & (phase1 < 4) & (phase2 > 4)) |\n",
    "    (~np.isnan(phase1) & ~np.isnan(phase2) & (phase1 > 4) & (phase2 < 4)) |\n",
    "    (~np.isnan(phase1) & ~np.isnan(phase2) & (phase1 - phase2 > 2)) |\n",
    "    (~np.isnan(phase1) & ~np.isnan(phase2) & (phase2 - phase1 > 2)) |\n",
    "    (~np.isnan(ourtypes1) & ~np.isnan(ourtypes2) & (ourtypes1 == ourtypes2)) |\n",
    "    (np.isnan(d21) & ~np.isnan(d12) & (d22 - d12 > 2)) |\n",
    "    (np.isnan(d21) & ~np.isnan(d12) & (d12 - d22 > 2)) |\n",
    "    (np.isnan(d12) & ~np.isnan(d21) & (d11 - d21 > 2)) |\n",
    "    (np.isnan(d12) & ~np.isnan(d21) & (d21 - d11 > 2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define phased1 and phased2 based on conditions\n",
    "phased1 = (\n",
    "    (~np.isnan(phase1) & ~np.isnan(phase2) & (phase1 < 4) & (phase2 > 4)) |\n",
    "    (~np.isnan(phase1) & ~np.isnan(phase2) & (phase2 - phase1 > 2) & (phase1 < 4)) |\n",
    "    (~np.isnan(ourtypes1) & ~np.isnan(ourtypes2) & (ourtypes1 == ourtypes2)) |\n",
    "    (np.isnan(d21) & ~np.isnan(d12) & (d12 - d22 > 2) & (d22 < 2)) |\n",
    "    (np.isnan(d12) & ~np.isnan(d21) & (d21 - d11 > 2) & (d11 < 2))\n",
    ")\n",
    "\n",
    "phased2 = (\n",
    "    (~np.isnan(phase1) & ~np.isnan(phase2) & (phase1 > 4) & (phase2 < 4)) |\n",
    "    (~np.isnan(phase1) & ~np.isnan(phase2) & (phase1 - phase2 > 2) & (phase2 < 4)) |\n",
    "    (np.isnan(d21) & ~np.isnan(d12) & (d22 - d12 > 2) & (d12 < 2)) |\n",
    "    (np.isnan(d12) & ~np.isnan(d21) & (d11 - d21 > 2) & (d21 < 2))\n",
    ")\n",
    "\n",
    "# Step 2: Assign alleles based on phased1 and phased2\n",
    "allele1 = np.full(len(ourtypes1), np.nan)\n",
    "allele2 = np.full(len(ourtypes1), np.nan)\n",
    "allele1[phased1] = ourtypes1[phased1]\n",
    "allele2[phased1] = ourtypes2[phased1]\n",
    "allele1[phased2] = ourtypes2[phased2]\n",
    "allele2[phased2] = ourtypes1[phased2]\n",
    "\n",
    "# Step 3: Iterate over extension sizes and refine phasing\n",
    "phased1old = phased1.copy()\n",
    "phased2old = phased2.copy()\n",
    "oldphase1 = phase1.copy()\n",
    "oldphase2 = phase2.copy()\n",
    "\n",
    "for extension in range(50, 1001, 50):\n",
    "    plt.scatter(oldphase1, oldphase2, c=1 + phased1.astype(int) + 2 * phased2.astype(int))\n",
    "    plt.show()\n",
    "\n",
    "    startandend = np.array([locs.min(), locs.max()])\n",
    "    startandend[0] -= extension\n",
    "    startandend[1] += extension\n",
    "    start32 = startandend[0] // 32 + 1\n",
    "    end32 = startandend[1] // 32 + 1\n",
    "    start = (start32 - 1) * 32 + 1\n",
    "    end = end32 * 32\n",
    "\n",
    "    tempIE = distinctHapsIE[:, start:end]\n",
    "    tempB = distinctHapsB[:, start32:end32]\n",
    "    temp = rhb_t[:, start32:end32]\n",
    "    temp2 = np.empty((temp.shape[0], tempIE.shape[1]))\n",
    "\n",
    "    cc = np.array([0.001] * 31 + [0.999])\n",
    "    \n",
    "    for i in range(temp.shape[1]):\n",
    "        temp2[:, i * 32:(i + 1) * 32] = tempIE[np.searchsorted(tempB[:, i], temp[:, i]), i * 32:(i + 1) * 32]\n",
    "        \n",
    "        cc2 = np.where(np.isnan(temp[:, i]))[0]\n",
    "        if len(cc2):\n",
    "            cc3 = np.tile(cc, (len(cc2), 1))\n",
    "            temp2[cc2, i * 32:(i + 1) * 32] = cc3\n",
    "        \n",
    "        needed = np.where(np.isnan(temp2[:, (i + 1) * 32 - 1]))[0]\n",
    "        if len(needed):\n",
    "            temp2[needed, i * 32:(i + 1) * 32] = translate(temp[needed, i])\n",
    "\n",
    "    temp2 = temp2[:, (startandend[0] - start):(startandend[1] - start)]\n",
    "\n",
    "    alleles = np.empty(len(temp2))\n",
    "    alleles[::2] = allele1\n",
    "    alleles[1::2] = allele2\n",
    "    nameset = np.unique(alleles[~np.isnan(alleles)])\n",
    "    \n",
    "    predmat = np.zeros((len(nameset), temp2.shape[1]))\n",
    "    for i, name in enumerate(nameset):\n",
    "        predmat[i, :] = np.mean(temp2[alleles == name, :], axis=0)\n",
    "    \n",
    "    predmatallele1 = np.zeros((len(ourtypes1), temp2.shape[1]))\n",
    "    predmatallele2 = np.zeros((len(ourtypes1), temp2.shape[1]))\n",
    "    \n",
    "    predmatallele1[np.isin(ourtypes1, nameset), :] = predmat[np.searchsorted(nameset, ourtypes1[np.isin(ourtypes1, nameset)]), :]\n",
    "    predmatallele2[np.isin(ourtypes2, nameset), :] = predmat[np.searchsorted(nameset, ourtypes2[np.isin(ourtypes2, nameset)]), :]\n",
    "\n",
    "    obsmatallele1 = temp2[::2, :]\n",
    "    obsmatallele2 = temp2[1::2, :]\n",
    "\n",
    "    dist11 = np.sum(np.abs(obsmatallele1 - predmatallele1) > 0.9, axis=1)\n",
    "    dist12 = np.sum(np.abs(obsmatallele1 - predmatallele2) > 0.9, axis=1)\n",
    "    dist21 = np.sum(np.abs(obsmatallele2 - predmatallele1) > 0.9, axis=1)\n",
    "    dist22 = np.sum(np.abs(obsmatallele2 - predmatallele2) > 0.9, axis=1)\n",
    "\n",
    "    w1 = np.zeros(len(dist11))\n",
    "    w1[dist11 < dist12] = 1\n",
    "    w1[dist11 > dist12] = -1\n",
    "    \n",
    "    w2 = np.zeros(len(dist21))\n",
    "    w2[dist22 < dist21] = 1\n",
    "    w2[dist22 > dist21] = -1\n",
    "\n",
    "    phase1b = dist11 + dist22\n",
    "    phase2b = dist12 + dist21\n",
    "    \n",
    "    # Define phased based on conditions\n",
    "    phased1b = (\n",
    "        (~np.isnan(phase1b) & ~np.isnan(phase2b) & (phase1b < phase2b)) |\n",
    "        (~np.isnan(ourtypes1) & ~np.isnan(ourtypes2) & (ourtypes1 == ourtypes2)) |\n",
    "        (np.isnan(d21) & ~np.isnan(d12) & (d12 - d22 > 2)) |\n",
    "        (np.isnan(d12) & ~np.isnan(d21) & (d21 - d11 > 2))\n",
    "    )\n",
    "\n",
    "    phased2b = (\n",
    "        (~np.isnan(phase1b) & ~np.isnan(phase2b) & (phase1b > phase2b)) |\n",
    "        (np.isnan(d21) & ~np.isnan(d12) & (d22 - d12 > 2)) |\n",
    "        (np.isnan(d12) & ~np.isnan(d21) & (d11 - d21 > 2))\n",
    "    )\n",
    "\n",
    "    # Update phasing\n",
    "    update = ~phased1 & ~phased2\n",
    "    phased1[update] = phased1b[update]\n",
    "    phased2[update] = phased2b[update]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
